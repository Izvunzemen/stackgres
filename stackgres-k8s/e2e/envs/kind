#!/bin/sh

KIND_NAME="${KIND_NAME:-kind}"
KIND_NODES="${KIND_NODES:-1}"
KIND_LOCK_PATH="${KIND_LOCK_PATH:-$TARGET_PATH/kind-lock}"
KIND_CONTAINERD_CACHE_PATH="${K8S_CACHE_PATH:-$KIND_CONTAINERD_CACHE_PATH}"
KIND_CONTAINERD_CACHE_RESET="${K8S_CACHE_RESET:-$KIND_CONTAINERD_CACHE_RESET}"
KIND_LOG_PATH="${KIND_LOG_PATH:-$TARGET_PATH/kind-logs}"
KIND_LOG_RESOURCES_POLICY_PATH="${KIND_LOG_RESOURCES_POLICY_PATH:-$TARGET_PATH/kind-apiserver-audit-policy}"
KIND_EXPANDABLE_STORAGE_CLASSNAME="${EXPANDABLE_STORAGE_CLASSNAME:-expandable-sc}"
KIND_0_15_0="${KIND_0_15_0:-kind-0.15.0}"
KIND_0_20_0="${KIND_0_20_0:-kind-0.20.0}"

check_kind_version() {
  if [ "$(echo "$K8S_VERSION" | tr . '\n' | head -n 2 | xargs -I @ printf '%05d' @)" \
      -ge "$(echo "1.21" | tr . '\n' | xargs -I @ printf '%05d' @)" ]
  then
    KIND="$KIND_0_20_0"
    if ! "$KIND" version | grep -q -F 'kind v0.20.0 '
    then
      echo "To run Kubernetes 1.21+ kind v0.20.0 is required"
      return 1
    fi
  else
    KIND="$KIND_0_15_0"
    if ! "$KIND" version | grep -q -F 'kind v0.15.0 '
    then
      echo "To run Kubernetes 1.20- kind v0.15.0 is required"
      return 1
    fi
  fi
}

get_k8s_env_version() {
  echo "Kind version $("$KIND" version | cut -d ' ' -f 2)"
  echo
}

update_k8s_config() {
  check_kind_version

  mkdir -p "$HOME/.kube"
  if [ "$K8S_FROM_DIND" = true ]
  then
    if docker network ls --format '{{ .Name }}' | grep -q '^kind$'
    then
      local CONTAINER_NAME
      CONTAINER_NAME="$(cat /proc/self/cgroup | grep '^1:name' | cut -d / -f 3)"
      CONTAINER_NAME="${CONTAINER_NAME:-$(hostname)}"
      docker inspect "$CONTAINER_NAME" \
        -f '{{ range $key,$value := .NetworkSettings.Networks }}{{ printf "%s\n" $key }}{{ end }}' \
        | grep -q '^kind$' \
        || docker network connect kind "$CONTAINER_NAME"
    fi
    local KIND_CONTROL_PLANE_IP
    KIND_CONTROL_PLANE_IP="$(docker inspect "$KIND_NAME-control-plane" \
      -f '{{ .NetworkSettings.Networks.kind.IPAddress }}')"
    "$KIND" get kubeconfig --name "$KIND_NAME" --internal \
      | sed "s/$KIND_NAME-control-plane/$KIND_CONTROL_PLANE_IP/" \
      > "$HOME/.kube/config-$KIND_NAME"
  else
    "$KIND" get kubeconfig --name "$KIND_NAME" \
      > "$HOME/.kube/config-$KIND_NAME"
  fi

  (
  export KUBECONFIG="${KUBECONFIG:-$HOME/.kube/config}"
  if [ -s "$KUBECONFIG" ]
  then
    KUBECONFIG="$HOME/.kube/config-$KIND_NAME":"$KUBECONFIG" \
      kubectl config view --raw > "$HOME/.kube/config-merged"
    mv "$HOME/.kube/config-merged" "$KUBECONFIG"
  else
    mv "$HOME/.kube/config-$KIND_NAME" "$KUBECONFIG"
  fi
  chmod 700 "$KUBECONFIG"
  )

  chmod 700 "$KUBECONFIG"
  # fix for Unable to connect to the server: x509: certificate is valid for <ips>, not <ip>
  kubectl config set "clusters.kind-$KIND_NAME.insecure-skip-tls-verify" --set-raw-bytes true
  kubectl config unset "clusters.kind-$KIND_NAME.certificate-authority-data"
}

reuse_k8s() {
  check_kind_version
  check_kind_image_exists

  try_function update_k8s_config

  if ! "$KIND" get clusters | grep -q "^$KIND_NAME$" \
      || ! docker inspect "$KIND_NAME-control-plane" -f '{{ .State.Status }}' \
        | grep -q -F 'running' \
      || ! docker inspect "$KIND_NAME-control-plane" -f '{{ .Config.Image }}' \
        | grep -q -F "kindest/node:v$(get_kind_image "${K8S_VERSION}")"
  then
    echo "Can not reuse kind environment $KIND_NAME"
    reset_k8s
    return
  fi

  echo "Reusing kind environment $KIND_NAME"
}

reset_k8s() {
  check_kind_version
  check_kind_image_exists

  if [ "$E2E_MOUNT_LOCAL_FOLDERS" = true ]
  then
    KIND_EXTRA_MOUNTS="$KIND_EXTRA_MOUNTS
      $(realpath "$PROJECT_PATH"/stackgres-k8s/src/operator/target/quarkus-app)
      $(realpath "$PROJECT_PATH"/stackgres-k8s/src/api-web/target/quarkus-app)
      $(realpath "$PROJECT_PATH"/stackgres-k8s/src/admin-ui/target/public)
      $(realpath "$PROJECT_PATH"/stackgres-k8s/src/jobs/target/quarkus-app)
      $(realpath "$PROJECT_PATH"/stackgres-k8s/src/cluster-controller/target/quarkus-app)
      $(realpath "$PROJECT_PATH"/stackgres-k8s/src/distributedlogs-controller/target/quarkus-app)"
  fi

  echo "Setting up kind environment $KIND_NAME..."

  if [ -n "$KIND_CONTAINERD_CACHE_PATH" ]
  then
    echo "Setting up kind containerd cache in $KIND_CONTAINERD_CACHE_PATH..."
    if [ "$KIND_CONTAINERD_CACHE_RESET" = true ]
    then
      docker run --rm -v "$KIND_CONTAINERD_CACHE_PATH:/containerd-cache" alpine \
        sh -c 'rm -rf /containerd-cache/*'
    fi
  fi

  if [ -n "$K8S_EXTRA_PORT" ]
  then
    echo "Setting up kind port $K8S_EXTRA_PORT..."
  fi

  delete_k8s
  if [ "$KIND_LOG_RESOURCES" = true ]
  then
    cat << EOF > "$KIND_LOG_RESOURCES_POLICY_PATH"
# Log all requests at the RequestResponse level.
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: RequestResponse
EOF
  fi
  cat << EOF > "$TARGET_PATH/kind-config.yaml"
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
$(
  if [ -n "$KIND_CONTAINERD_CACHE_PATH" ] || \
    docker system info 2> /dev/null | grep -q "Backing Filesystem: \(zfs\|btrfs\)"
  then
    cat << INNER_EOF
containerdConfigPatches:
- |-
$(
  if [ -n "$KIND_CONTAINERD_CACHE_PATH" ]
  then
    cat << INNER_INNER_EOF
 
 root = "/containerd-cache"
INNER_INNER_EOF
  fi
  if docker system info 2> /dev/null | grep -q "Backing Filesystem: zfs" \
    || ([ -d "$KIND_CONTAINERD_CACHE_PATH" ] \
      && df -T "$KIND_CONTAINERD_CACHE_PATH" | tail -n 1 | tr -s ' ' | cut -d ' ' -f 2 | grep -q '^zfs$')
  then
    cat << INNER_INNER_EOF
 [plugins."io.containerd.grpc.v1.cri".containerd]
 snapshotter = "zfs"
INNER_INNER_EOF
  fi
  if docker system info 2> /dev/null | grep -q "Backing Filesystem: btrfs" \
    || ([ -d "$KIND_CONTAINERD_CACHE_PATH" ] \
      && df -T "$KIND_CONTAINERD_CACHE_PATH" | tail -n 1 | tr -s ' ' | cut -d ' ' -f 2 | grep -q '^btrfs$')
  then
    cat << INNER_INNER_EOF
 [plugins."io.containerd.grpc.v1.cri".containerd]
 snapshotter = "btrfs"
INNER_INNER_EOF
  fi
)
INNER_EOF
  fi
)
networking:
  disableDefaultCNI: true
  apiServerAddress: "0.0.0.0"
nodes:
- role: control-plane
$(
  if [ "$KIND_LOG_RESOURCES" = true ]
  then
    cat << INNER_EOF
  kubeadmConfigPatches:
  - |
    kind: ClusterConfiguration
    apiServer:
        # enable auditing flags on the API server
        extraArgs:
          audit-log-path: /var/log/kubernetes/kube-apiserver-audit.log
          audit-policy-file: /etc/kubernetes/policies/audit-policy.yaml
        # mount new files / directories on the control plane
        extraVolumes:
          - name: audit-policies
            hostPath: /etc/kubernetes/policies
            mountPath: /etc/kubernetes/policies
            readOnly: true
            pathType: "DirectoryOrCreate"
          - name: "audit-logs"
            hostPath: "/var/log/kubernetes"
            mountPath: "/var/log/kubernetes"
            readOnly: false
            pathType: DirectoryOrCreate
INNER_EOF
  fi
  if [ -n "$K8S_EXTRA_PORT" ]
  then
    cat << INNER_EOF
  extraPortMappings:
  - containerPort: $(echo "$K8S_EXTRA_PORT" | cut -d : -f 1)
    hostPort: $(echo "$K8S_EXTRA_PORT" | cut -d : -f 2)
    listenAddress: "$(echo "$K8S_EXTRA_PORT" | cut -d : -f 3)"
    protocol: "$(echo "$K8S_EXTRA_PORT" | cut -d : -f 4)"
INNER_EOF
  fi
  if [ -n "$KIND_EXTRA_MOUNTS" ] \
    || [ -n "$KIND_CONTAINERD_CACHE_PATH" ] \
    || [ "$KIND_LOG" = true ] \
    || [ "$KIND_LOG_RESOURCES" = true ]
  then
    cat << INNER_EOF
  extraMounts:
INNER_EOF
  fi
  if [ -n "$KIND_EXTRA_MOUNTS" ]
  then
    for KIND_EXTRA_MOUNT in $KIND_EXTRA_MOUNTS
    do
      cat << INNER_EOF
  - hostPath: $KIND_EXTRA_MOUNT
    containerPath: $KIND_EXTRA_MOUNT
INNER_EOF
    done
  fi
  if [ -n "$KIND_CONTAINERD_CACHE_PATH" ]
  then
    mkdir -p "$KIND_CONTAINERD_CACHE_PATH"
    cat << INNER_EOF
  - hostPath: $KIND_CONTAINERD_CACHE_PATH
    containerPath: /containerd-cache
INNER_EOF
  fi
  if [ "$KIND_LOG" = true ]
  then
    mkdir -p "$KIND_LOG_PATH"
    cat << INNER_EOF
  - hostPath: $KIND_LOG_PATH
    containerPath: /var/log
INNER_EOF
  fi
  if [ "$KIND_LOG_RESOURCES" = true ]
  then
    cat << INNER_EOF
  - hostPath: $KIND_LOG_RESOURCES_POLICY_PATH
    containerPath: /etc/kubernetes/policies/audit-policy.yaml
    readOnly: true
INNER_EOF
  fi
  for KIND_NODE in $(seq 2 "$KIND_NODES")
  do
    cat << INNER_EOF
- role: worker
INNER_EOF
  done
)
EOF

  try_function flock "$KIND_LOCK_PATH" \
    "$KIND" create cluster --name "$KIND_NAME" --config "$TARGET_PATH/kind-config.yaml" \
    --image "kindest/node:v$(get_kind_image "${K8S_VERSION}")"
  if ! "$RESULT" && [ -n "$KIND_CONTAINERD_CACHE_PATH" ] && [ "$KIND_CONTAINERD_CACHE_RESET" != true ]
  then
    echo "Kind failed to create cluster with cache enabled. Resetting cache and retrying!"
    KIND_CONTAINERD_CACHE_RESET=true reset_k8s
    return
  fi

  if [ "$KIND_INSTALL_NFS" = "true" ]
  then
    echo "Setting up NFT tools for kind..."
    "$KIND" get nodes --name "$KIND_NAME" \
      | xargs -r -n 1 -I % -P "$E2E_PARALLELISM" sh -ec "
      docker exec '%' sh -c 'DEBIAN_FRONTEND=noninteractive apt-get update -y -qq < /dev/null > /dev/null'
      docker exec '%' sh -c 'DEBIAN_FRONTEND=noninteractive apt-get install -y -qq nfs-common < /dev/null > /dev/null'
      "
  fi

  update_k8s_config

  if [ "$(echo "$K8S_VERSION" | tr . '\n' | head -n 2 | xargs -I @ printf '%05d' @)" \
      -eq "$(echo "1.12" | tr . '\n' | xargs -I @ printf '%05d' @)" ]
  then
    echo "Patch coredns to version 1.3.1 (see https://github.com/coredns/coredns/issues/2391)..."
    kubectl patch deployment -n kube-system coredns --type json \
      --patch '[{"op":"replace","path":"/spec/template/spec/containers/0/image","value":"k8s.gcr.io/coredns:1.3.1"}]'
  fi

  echo "Setting up calico for kind..."
  until kubectl get node --template '{{ if (index .items 0).spec.podCIDR }}true{{ end }}' | grep -q 'true'
  do
    sleep 1
  done
  K8S_POD_CIDR="$(kubectl get node --template '{{ (index .items 0).spec.podCIDR }}')"
  if [ "$(echo "$K8S_VERSION" | tr . '\n' | head -n 2 | xargs -I @ printf '%05d' @)" \
      -ge "$(echo "1.22" | tr . '\n' | xargs -I @ printf '%05d' @)" ]
  then
    kubectl create -f https://docs.projectcalico.org/archive/v3.24/manifests/tigera-operator.yaml
    kubectl create -f https://docs.projectcalico.org/archive/v3.24/manifests/custom-resources.yaml
    kubectl patch installations.operator.tigera.io default --type json \
      -p '[{"op":"replace","path":"/spec/calicoNetwork/ipPools/0/cidr","value":"'"$K8S_POD_CIDR"'"}]'
  else
    kubectl apply -f https://docs.projectcalico.org/v3.12/manifests/calico.yaml
    kubectl -n kube-system set env daemonset/calico-node CALICO_IPV4POOL_CIDR="$K8S_POD_CIDR"
    kubectl -n kube-system set env daemonset/calico-node FELIX_IGNORELOOSERPF=true
  fi
  echo "...done"

  if [ "$ENABLE_METRIC_SERVER" = true ]
  then
    setup_metric_server
  fi
}

setup_metric_server() {
  echo "Setting up metric server for kind..."
  kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
  kubectl patch -n kube-system deploy metrics-server --type json \
    -p '[{"op":"add","path":"/spec/template/spec/containers/0/args/5","value":"--kubelet-insecure-tls"}]'
  echo "...done"
}

delete_k8s() {
  check_kind_version

  if "$KIND" get clusters | grep -q "^$KIND_NAME$"
  then
    echo "Deleting kind environment $KIND_NAME..."

    "$KIND" delete cluster --name "$KIND_NAME" || true

    echo "...done"
  fi
}

load_image_k8s() {
  check_kind_version

  local IMAGE_ID
  IMAGE_ID="$( (docker inspect --format '{{ .ID }}' "$1" 2>/dev/null || printf unknown) | grep -v '^$')"
  local KIND_IMAGE_ID
  KIND_IMAGE_ID="$( (docker exec "${KIND_NAME}-control-plane" crictl inspecti -o json "$1" 2>/dev/null || printf '{"status": {"id": "unknown"}}') | jq -r '.status.id' | grep -v '^$')"
  if [ "$IMAGE_ID" = unknown ] && [ "$KIND_IMAGE_ID" != unknown ]
  then
    echo "Image $1 already loaded in kind environemnt $KIND_NAME"
    return
  fi
  if [ "$KIND_IMAGE_ID" = "$IMAGE_ID" ] && [ "$IMAGE_ID" != unknown ]
  then
    echo "Image $1 already loaded in kind environemnt $KIND_NAME"
    return
  fi
  "$KIND" load docker-image --name "$KIND_NAME" "$1"

  echo "Loaded image $1 in kind environemnt $KIND_NAME"
}

pull_image_k8s() {
  check_kind_version

  local IMAGE_ID
  IMAGE_ID="$( (docker inspect --format '{{ .ID }}' "$1" 2>/dev/null || printf unknown) | grep -v '^$')"
  local KIND_IMAGE_ID
  KIND_IMAGE_ID="$( (docker exec "${KIND_NAME}-control-plane" crictl inspecti -o json "$1" 2>/dev/null || printf '{"status": {"id": "unknown"}}') | jq -r '.status.id' | grep -v '^$')"
  if [ "$IMAGE_ID" = unknown ] && [ "$KIND_IMAGE_ID" != unknown ]
  then
    echo "Image $1 already loaded in kind environemnt $KIND_NAME"
    return
  fi
  if [ "$KIND_IMAGE_ID" = "$IMAGE_ID" ] && [ "$IMAGE_ID" != unknown ]
  then
    echo "Image $1 already loaded in kind environemnt $KIND_NAME"
    return
  fi

  local AUTH
  AUTH="$(jq -r '.auths|to_entries|.[]|.key + "|" + .value.auth' "${HOME}/.docker/config.json" \
    | grep -F "${1%%/*}" | head -n 1 | cut -d '|' -f 2)"
  if [ -n "$AUTH" ]
  then
    docker exec "${KIND_NAME}-control-plane" ctr -n k8s.io i pull --user "$(printf %s "$AUTH" | base64 -d)" "$1" > /dev/null
  else
    docker exec "${KIND_NAME}-control-plane" ctr -n k8s.io i pull "$1" > /dev/null
  fi

  echo "Pulled image $1 in kind environemnt $KIND_NAME"
}

tag_image_k8s() {
  check_kind_version

  docker exec "${KIND_NAME}-control-plane" ctr -n k8s.io images tag --force "$1" "$2"

  echo "Tagged image $1 as $2 in kind environemnt $KIND_NAME"
}

load_certificate_k8s() {
  check_kind_version

  echo "Loading certificate $1 in kind environemnt $KIND_NAME..."

  "$KIND" get nodes --name "$KIND_NAME" \
    | xargs -r -n 1 -I % -P "$E2E_PARALLELISM" sh -ec "
    docker cp '$1' '%':/usr/local/share/ca-certificates/validator.crt
    docker exec '%' sh -c update-ca-certificates
    "

  echo "...done"
}

excluded_namespaces() {
  echo "calico-apiserver"
  echo "calico-system"
  echo "default"
  echo "kube-.*"
  echo "local-path-storage"
  echo "tigera-operator"
}

excluded_customresourcedefinitions() {
  echo ".*\.crd\.projectcalico\.org"
  echo ".*\.operator\.tigera\.io"
}

excluded_podsecuritypolicies() {
  echo "calico-.*"
  echo "tigera-operator"
}

excluded_clusterroles() {
  echo "admin"
  echo "calico-.*"
  echo "cluster-admin"
  echo "edit"
  echo "kubeadm:.*"
  echo "local-path-provisioner-role"
  echo "system:.*"
  echo "tigera-operator"
  echo "view"
}

excluded_clusterrolebindings() {
  echo "calico-.*"
  echo "cluster-admin"
  echo "kubeadm:.*"
  echo "local-path-provisioner-bind"
  echo "system:.*"
  echo "tigera-operator"
}

get_k8s_versions() {
  get_kind_images | cut -d @ -f 1 | sed 's/^v//'
}

check_kind_image_exists() {
  try_function get_kind_image "${K8S_VERSION}" > /dev/null 2>&1
  if ! "$RESULT"
  then
    echo "Kind image for k8s version ${K8S_VERSION} not found."
    echo "Available images exists only for versions: $(get_k8s_versions | tr '\n' ' ' | sed 's/ /, /g')"
    return 1
  fi
}

get_kind_image() {
  get_kind_images | sed 's/^v//' | grep "^$1[.@]"
}

get_kind_images() {
  cat << EOF
v1.27.3@sha256:3966ac761ae0136263ffdb6cfd4db23ef8a83cba8a463690e98317add2c9ba72
v1.26.6@sha256:6e2d8b28a5b601defe327b98bd1c2d1930b49e5d8c512e1895099e4504007adb
v1.25.11@sha256:227fa11ce74ea76a0474eeefb84cb75d8dad1b08638371ecf0e86259b35be0c8
v1.24.15@sha256:7db4f8bea3e14b82d12e044e25e34bd53754b7f2b0e9d56df21774e6f66a70ab
v1.23.17@sha256:59c989ff8a517a93127d4a536e7014d28e235fb3529d9fba91b3951d461edfdb
v1.22.17@sha256:f5b2e5698c6c9d6d0adc419c0deae21a425c07d81bbf3b6a6834042f25d4fba2
v1.21.14@sha256:8a4e9bb3f415d2bb81629ce33ef9c76ba514c14d707f9797a01e3216376ba093
v1.20.15@sha256:d67de8f84143adebe80a07672f370365ec7d23f93dc86866f0e29fa29ce026fe
v1.19.16@sha256:707469aac7e6805e52c3bde2a8a8050ce2b15decff60db6c5077ba9975d28b98
v1.18.20@sha256:61c9e1698c1cb19c3b1d8151a9135b379657aee23c59bde4a8d87923fcb43a91
EOF
}

create_expandable_storage_class_k8s(){
  cat << EOF | kubectl apply -f - > /dev/null
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: $KIND_EXPANDABLE_STORAGE_CLASSNAME
provisioner: rancher.io/local-path
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
EOF

  printf '%s' "$KIND_EXPANDABLE_STORAGE_CLASSNAME"
}
