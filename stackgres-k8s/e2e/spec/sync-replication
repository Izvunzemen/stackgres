#!/bin/sh

. "$SPEC_PATH/abstract/metrics"
. "$SPEC_PATH/abstract/dbops-restart"

e2e_test_install() {
  create_or_replace_cluster "$CLUSTER_NAME" "$CLUSTER_NAMESPACE" "3" \
    --set cluster.replication.mode=sync \
    --set cluster.replication.role=ha-read \
    --set cluster.replication.syncInstances=2 \
    --set cluster.replication.groups[0].instances=1 \
    --set cluster.replication.groups[0].role=none

  deploy_curl_pod "$CLUSTER_NAMESPACE"

  wait_pods_running "$CLUSTER_NAMESPACE" "4"
  wait_cluster "$CLUSTER_NAME" "$CLUSTER_NAMESPACE"
}

e2e_test() {
  run_test "Checking that synchronous replication is working" check_sync_replication_is_working

  run_test "Checking that metrics are exported" check_metrics

  run_test "Checking that replica in ha-read group is exposed in replicas service" check_replica_in_ha_read_group_not_in_replicas_service

  run_test "Checking that replica in none group is not exposed in replicas service" check_replica_in_none_group_not_in_replicas_service

  run_test "Checking that replica in none group is not elegible as primary" check_replica_in_none_group_not_elegible_as_primary

  run_test "Checking that replica in readonly group is exposed in replicas service after changing role" check_replica_in_readonly_group_in_replicas_service_after_changing_role

  run_test "Checking that old primary in ha group is not exposed in replicas service after changing role" check_old_primary_in_ha_group_not_in_replicas_service_after_changing_role

  run_test "Checking that strict synchronous replication is working" check_strict_sync_replication_is_working

  run_test "Checking that cluster can restart without replicas in any ha or ha-read group" check_cluster_can_restart_without_replicas_in_any_ha_group
}

check_sync_replication_is_working() {
  wait_until check_connectivity -i 0

  local SYNCHRONOUS_STANDBY_NAMES
  SYNCHRONOUS_STANDBY_NAMES="$(kubectl exec -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-0" -c postgres-util -- \
    psql -At -c 'SHOW synchronous_standby_names')"
  if echo "$SYNCHRONOUS_STANDBY_NAMES" | grep -q '^"[^"]\+ [^"]\+"$'
  then
    echo "SUCCESS: sync replication is set for primary"
  else
    echo "FAIL: sync replication is not set for primary"
    return 1
  fi

  local RESULT EXIT_CODE
  try_function run_query -p 5432 -h "$CLUSTER_NAME-primary" -i 1 -q "CREATE DATABASE test;"
  if "$RESULT"
  then
    echo "SUCCESS: It's possible to create a database in the primary node"
  else
    echo "FAIL: It should be possible to create a database in the primary node" 
    return 1
  fi

  wait_until check_connectivity -i 1
  try_function run_query -p 5432 -i 0 -h "$CLUSTER_NAME-replicas" -q "CREATE TABLE fibonacci(num integer);" -d test > "${LOG_PATH}/test1.log"
  if "$RESULT"
  then
    echo "FAIL: It's possible to create a table in the replica node"
    return 1
  else
    echo "SUCCESS: It's not be possible to create a table in the replica node" 
  fi

  run_query -p 5432 -h "$CLUSTER_NAME-primary" -i 1 -q "CREATE TABLE fibonacci(num integer);" -d test
  run_query -p 5432 -h "$CLUSTER_NAME-primary" -i 1 -q "INSERT INTO fibonacci(num) VALUES (1);" -d test
  run_query -p 5432 -h "$CLUSTER_NAME-primary" -i 1 -q "INSERT INTO fibonacci(num) VALUES (2);" -d test
  run_query -p 5432 -h "$CLUSTER_NAME-primary" -i 1 -q "INSERT INTO fibonacci(num) VALUES (3);" -d test

  PRIMARY_RESPONSE="$(run_query -p 5432 -i 1 -h "$CLUSTER_NAME-primary" -q "SELECT num FROM fibonacci ORDER BY num;" -d "test")"
  REPLICA_RESPONSE="$(run_query -p 5432 -i 0 -h "$CLUSTER_NAME-replicas" -q "SELECT num FROM fibonacci ORDER BY num;" -d "test")"

  if [ "$(echo "$PRIMARY_RESPONSE" | tr -d '\n')" = "123" ]
  then
    echo "SUCCESS: inserts on the primary with sync replication where sucessful."
  else
    echo "FAIL: inserts on the primary with sync replication where not sucessful."
    return 1
  fi

  if [ "$(echo "$PRIMARY_RESPONSE" | tr -d '\n')" = "$(echo "$REPLICA_RESPONSE" | tr -d '\n')" ]
  then
    echo "SUCCESS: sync replication is working"
  else
    echo "FAIL: sync replication is not working. The records don't match between primary and replica for the fibonacci table"
    return 1
  fi
}

check_replica_in_ha_read_group_not_in_replicas_service() {
  local RESULT EXIT_CODE
  try_function wait_until eval 'check_pod_ip_exposed_by_service "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-1" "$CLUSTER_NAME-replicas"'
  if "$RESULT"
  then
    echo "SUCCESS: first replica IP was exposed by replicas sevices"
  else
    echo "FAIL: first replica IP was not exposed by replicas sevices"
    return 1
  fi
}

check_replica_in_none_group_not_in_replicas_service() {
  local RESULT EXIT_CODE
  try_function wait_until eval '! check_pod_ip_exposed_by_service "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-2" "$CLUSTER_NAME-replicas"'
  if "$RESULT"
  then
    echo "SUCCESS: second replica IP was not exposed by replicas sevices"
  else
    echo "FAIL: second replica IP was exposed by replicas sevices"
    return 1
  fi
}

check_replica_in_none_group_not_elegible_as_primary() {
  kubectl patch sgcluster -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME" --type json \
    -p '[{"op":"add","path":"/spec/pods/scheduling","value":{"nodeSelector":{"'"$(random_string)"'": "'"$(random_string)"'"}}}]'
  kubectl delete pod -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-0"
  local RESULT EXIT_CODE
  try_function wait_until eval '[ $(kubectl get pod -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-1" --template "{{ .metadata.labels.role }}") = master ]'
  if "$RESULT"
  then
    echo "SUCCESS: first replica IP was elected as primary"
  else
    echo "FAIL: first replica IP was not elected as primary"
    return 1
  fi
}

check_replica_in_readonly_group_in_replicas_service_after_changing_role() {
  kubectl patch sgcluster -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME" --type json \
    -p '[{"op":"replace","path":"/spec/replication/groups/0/role","value":"readonly"}]'
  local RESULT EXIT_CODE
  try_function wait_until eval 'check_pod_ip_exposed_by_service "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-2" "$CLUSTER_NAME-replicas"'
  if "$RESULT"
  then
    echo "SUCCESS: second replica IP was exposed by replicas sevices"
  else
    echo "FAIL: second replica IP was not exposed by replicas sevices"
    return 1
  fi
}

check_old_primary_in_ha_group_not_in_replicas_service_after_changing_role() {
  kubectl patch sgcluster -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME" --type json \
    -p '[{"op":"replace","path":"/spec/replication/role","value":"ha"},
         {"op":"remove","path":"/spec/pods/scheduling"}]'
  until kubectl wait -n "$CLUSTER_NAMESPACE" pod "$CLUSTER_NAME-0" --for=condition=PodScheduled --timeout 0
  do
    kubectl delete pod -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-0"
  done
  wait_pods_running "$CLUSTER_NAMESPACE" "4"
  local RESULT EXIT_CODE
  try_function wait_until eval '! check_pod_ip_exposed_by_service "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-0" "$CLUSTER_NAME-replicas"'
  if "$RESULT"
  then
    echo "SUCCESS: old primary IP was not exposed by replicas sevices"
  else
    echo "FAIL: old primary IP was exposed by replicas sevices"
    return 1
  fi
}

check_strict_sync_replication_is_working() {
  kubectl patch sgcluster -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME" --type json \
    -p '[{"op":"replace","path":"/spec/replication/mode","value":"strict-sync"},
         {"op":"replace","path":"/spec/replication/role","value":"ha-read"},
         {"op":"replace","path":"/spec/replication/groups/0/instances","value":2},
         {"op":"replace","path":"/spec/replication/groups/0/role","value":"readonly"}]'
  local RESULT EXIT_CODE
  try_function wait_until -t 10 eval 'kubectl wait -n "$CLUSTER_NAMESPACE" sgcluster "$CLUSTER_NAME" --for=condition=PendingRestart --timeout 0'
  if "$RESULT"
  then
    echo "FAIL: cluster is pending restart after changing the replication mode"
    return 1
  else
    echo "SUCCESS: cluster is not pending restart after changing the replication mode"
  fi

  kubectl exec -ti -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-0" -c patroni -- \
    patronictl switchover "$CLUSTER_NAME" --master "$CLUSTER_NAME-1" --candidate "$CLUSTER_NAME-0" --force

  local RESULT EXIT_CODE
  try_function wait_until eval 'kubectl exec -n "$CLUSTER_NAMESPACE" "$CLUSTER_NAME-0" -c postgres-util -- \
    psql -At -c "SHOW synchronous_standby_names" | grep -q "^\"[^\"]\+\"$"'
  if "$RESULT"
  then
    echo "SUCCESS: sync replication is set for primary"
  else
    echo "FAIL: strict sync replication is not set for primary"
    return 1
  fi

  run_query -p 5432 -h "$CLUSTER_NAME-primary" -i 1 -q "CREATE TABLE fibonacci_strict(num integer);" -d test
  run_query -p 5432 -h "$CLUSTER_NAME-primary" -i 1 -q "INSERT INTO fibonacci_strict(num) VALUES (1);" -d test
  run_query -p 5432 -h "$CLUSTER_NAME-primary" -i 1 -q "INSERT INTO fibonacci_strict(num) VALUES (2);" -d test
  run_query -p 5432 -h "$CLUSTER_NAME-primary" -i 1 -q "INSERT INTO fibonacci_strict(num) VALUES (3);" -d test

  PRIMARY_RESPONSE="$(run_query -p 5432 -i 1 -h "$CLUSTER_NAME-primary" -q "SELECT num FROM fibonacci_strict ORDER BY num;" -d "test")"
  REPLICA_RESPONSE="$(run_query -p 5432 -i 0 -h "$CLUSTER_NAME-replicas" -q "SELECT num FROM fibonacci_strict ORDER BY num;" -d "test")"

  if [ "$(echo "$PRIMARY_RESPONSE" | tr -d '\n')" = "123" ]
  then
    echo "SUCCESS: inserts on the primary with strict sync replication where sucessful."
  else
    echo "FAIL: inserts on the primary with strict sync replication where not sucessful."
    return 1
  fi

  if [ "$(echo "$PRIMARY_RESPONSE" | tr -d '\n')" = "$(echo "$REPLICA_RESPONSE" | tr -d '\n')" ]
  then
    echo "SUCCESS: strict sync replication is working"
  else
    echo "FAIL: strict sync replication is not working. The records don't match between primary and replica for the fibonacci_strict table"
    return 1
  fi
}

check_cluster_can_restart_without_replicas_in_any_ha_group() {
  DBOPS_NAME="$(get_sgdbops_name restart)"

  cat << EOF | kubectl create -f -
apiVersion: stackgres.io/v1
kind: SGDbOps
metadata:
  name: $DBOPS_NAME
  namespace: $CLUSTER_NAMESPACE
spec:
  sgCluster: $CLUSTER_NAME
  op: restart
  restart:
    method: InPlace
EOF

  check_restart_without_data

  kubectl delete sgdbops -n "$CLUSTER_NAMESPACE" "$DBOPS_NAME"
}

check_pod_ip_exposed_by_service() {
  local CLUSTER_NAMESPACE="$1"
  local POD_NAME="$2"
  local SERVICE_NAME="$3"
  local POD_2_IP SERVICE_IPS
  POD_2_IP="$(kubectl get pod -n "$CLUSTER_NAMESPACE" "$POD_NAME" --template '{{ .status.podIP }}')"
  SERVICE_IPS="$(kubectl get endpoints -n "$CLUSTER_NAMESPACE" "$SERVICE_NAME" \
    --template '{{ range .subsets }}{{ range .addresses }}{{ printf "%s\n" .ip }}{{ end }}{{ end }}')"
  if echo "$SERVICE_IPS" | grep -qxF "$POD_2_IP"
  then
    echo "SUCCESS: pod $POD_NAME IP was exposed by sevice $SERVICE_NAME"
  else
    echo "FAIL: pod $POD_NAME IP was not exposed by sevice $SERVICE_NAME"
    return 1
  fi
}
