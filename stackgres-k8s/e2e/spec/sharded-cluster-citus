#!/bin/sh

. "$SPEC_PATH/abstract/patroni"

. "$SPEC_PATH/abstract/sql-scripts"

. "$SPEC_PATH/abstract/backup"

e2e_test_extra_hash() {
  "$SHELL" "$PROJECT_PATH/stackgres-k8s/ci/build/build-functions.sh" path_hash \
    "$(realpath --relative-to "$PROJECT_PATH" "$SPEC_PATH/abstract/patroni")"
  "$SHELL" "$PROJECT_PATH/stackgres-k8s/ci/build/build-functions.sh" path_hash \
    "$(realpath --relative-to "$PROJECT_PATH" "$SPEC_PATH/abstract/sql-scripts")"
  "$SHELL" "$PROJECT_PATH/stackgres-k8s/ci/build/build-functions.sh" path_hash \
    "$(realpath --relative-to "$PROJECT_PATH" "$SPEC_PATH/abstract/backup")"
  "$SHELL" "$PROJECT_PATH/stackgres-k8s/ci/build/build-functions.sh" path_hash \
    "$(realpath --relative-to "$PROJECT_PATH" "$SPEC_PATH/sql-scripts.sakila.sql")"
}

e2e_test_install() {
  install_minio

  cat << 'EOF' | kubectl create -n "$CLUSTER_NAMESPACE" secret generic sql-scripts-sakila-user \
    --from-literal=create-sakila-user.sql="$(cat)"
DO $$
BEGIN
  IF NOT EXISTS (SELECT * FROM pg_roles WHERE rolname = 'sakila') THEN
    EXECUTE 'CREATE USER sakila WITH PASSWORD ''sakila'';';
  END IF;
  IF NOT EXISTS (SELECT * FROM pg_dist_authinfo WHERE rolename = 'sakila') THEN
    INSERT INTO pg_dist_authinfo (nodeid, rolename, authinfo) VALUES (0, 'sakila', 'password=sakila');
  END IF;
END$$;
EOF

  kubectl create -n "$CLUSTER_NAMESPACE" configmap sql-scripts-sakila-schema \
    --from-file=create-sakila-schema.sql="$SPEC_PATH/sql-scripts.sakila.sql"

  create_or_replace_sharded_cluster "$CLUSTER_NAME" "$CLUSTER_NAMESPACE" "3" "2"

  deploy_curl_pod "$CLUSTER_NAMESPACE"

  wait_pods_running "$CLUSTER_NAMESPACE" 8
  wait_sharded_cluster "$CLUSTER_NAME" "$CLUSTER_NAMESPACE"
}

e2e_test() {
  run_test "Checking that is possible to connect using services is working" service_check

  run_test "Checking that sharded technology is configured and working" sharded_check

  run_test "Check that pgbouncer database is accesible using the service" pgbouncer_database_check

  run_test "Checking that managed SQL is working" check_managed_sql_is_working

  run_test "Checking that backup is working" check_backup_is_working
}

service_check() {
  RESPONSE_PRIMARY="$(run_query -c "$CLUSTER_NAME-coord" -h "$CLUSTER_NAME" -i 1 -p 5432)"

  if [ "$RESPONSE_PRIMARY" = "1" ]
  then
    echo "SUCCESS: Connections are possible using services"
  else
    echo "FAIL: Cannot connect to primary db using a kubernetes service"
    return 1
  fi
}

sharded_check() {
  local RESULT EXIT_CODE
  try_function wait_until eval 'run_query -c "$CLUSTER_NAME-coord" -h "$CLUSTER_NAME" -i 1 -p 5432 \
    -d citus -q "SELECT COUNT(*) FROM master_get_active_worker_nodes()" | grep -xF 2'

  if [ "$EXIT_CODE" = 0 ]
  then
    echo "SUCCESS: Sharding coordinator service is working"
  else
    echo "FAIL: Sharding coordinator service is not working"
    return 1
  fi

  try_function wait_until eval 'run_query -c "$CLUSTER_NAME-coord" -h "$CLUSTER_NAME-primary" -i 1 -p 5432 \
    -d citus -q "SELECT COUNT(*) FROM master_get_active_worker_nodes()" | grep -xF 2'

  if [ "$EXIT_CODE" = 0 ]
  then
    echo "SUCCESS: Sharding primary coordinator service is working"
  else
    echo "FAIL: Sharding primary coordinator service is not working"
    return 1
  fi

  try_function wait_until eval 'run_query -c "$CLUSTER_NAME-coord" -h "$CLUSTER_NAME-shards" -i 1 -p 5432 \
    -d citus -q "SELECT pg_is_in_recovery()" | grep -xF f'

  if [ "$EXIT_CODE" = 0 ]
  then
    echo "SUCCESS: Sharding shards service is working"
  else
    echo "FAIL: Sharding shards service is not working"
    return 1
  fi

  try_function wait_until eval 'run_query -c "$CLUSTER_NAME-coord" -h "$CLUSTER_NAME-primary" -i 1 -p 5432 \
    -d citus -q "SELECT setting FROM pg_settings WHERE name = '"'"'citus.max_client_connections'"'"'" | grep -xF 30'

  if [ "$EXIT_CODE" = 0 ]
  then
    echo "SUCCESS: Setting citus.max_client_connections is correctly configured"
  else
    echo "FAIL: Setting citus.max_client_connections is not correctly configured"
    return 1
  fi
}

pgbouncer_database_check() {
  if kubectl exec -n "$CLUSTER_NAMESPACE" "${CLUSTER_NAME}-coord-0" -c "postgres-util" -- env \
    PGPASSWORD="$(kubectl -n "$CLUSTER_NAMESPACE" get secrets "$CLUSTER_NAME-coord" \
      -o jsonpath='{.data.pgbouncer-admin-password}' | base64 -d)" \
    PGCONNECT_TIMEOUT="$((5 + E2E_TIMEOUT / 10))" \
    psql -t -A -U pgbouncer_admin -d pgbouncer -h "$CLUSTER_NAME" -c "SHOW FDS" >/dev/null
  then
    echo "SUCCESS: psql could connect to the pgbouncer database with pgobuncer_admin using service"
  else
    echo "FAIL: psql could not connect to the pgbouncer database with pgobuncer_admin using service"
    return 1
  fi

  if kubectl exec -n "$CLUSTER_NAMESPACE" "${CLUSTER_NAME}-coord-0" -c "postgres-util" -- env \
    PGPASSWORD="$(kubectl -n "$CLUSTER_NAMESPACE" get secrets "$CLUSTER_NAME-coord" \
      -o jsonpath='{.data.pgbouncer-stats-password}' | base64 -d)" \
    PGCONNECT_TIMEOUT="$((5 + E2E_TIMEOUT / 10))" \
    psql -t -A -U pgbouncer_stats -d pgbouncer -h "$CLUSTER_NAME" -c "SHOW VERSION" >/dev/null
  then
    echo "SUCCESS: psql could connect to the pgbouncer database with pgobuncer_stats using service"
  else
    echo "FAIL: psql could not connect to the pgbouncer database with pgobuncer_stats using service"
    return 1
  fi
}

check_managed_sql_is_working() {
  local CLUSTER_NAME="$CLUSTER_NAME-coord"
  local NODE=0
  local DATABASE=citus
  check_user_on_primary
  check_database_on_primary
  check_schema_on_primary
}

check_backup_is_working() {
  local BACKUP_NAME
  local BASE_CLUSTER_NAME="$CLUSTER_NAME"
  local CLUSTER_NAME
  local NODE=0
  for CLUSTER_NAME in "$BASE_CLUSTER_NAME-coord" "$BASE_CLUSTER_NAME-shard0" "$BASE_CLUSTER_NAME-shard1"
  do
    check_wal_archive 0

    check_manual_backup 0

    BACKUP_NAME="$(get_sgbackup_name "${CLUSTER_NAME}-${NODE}-$(shuf -i 0-65535 -n 1)")"
    create_backup "$BACKUP_NAME" false
    wait_backup_is_completed "$BACKUP_NAME" "$NODE"

    check_timelines

    check_control_data
  done
}
